{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros cargados: 1000 filas y 7 columnas\n",
      "Después de convertir UTM a lat/lon:\n",
      "                 time             j              i    Elevation  Speed  \\\n",
      "0 2020-01-01 22:27:09  2.143059e+06  595533.288961  1108.694285   61.0   \n",
      "1 2020-01-01 22:27:10  2.143059e+06  595540.878338  1113.924285   22.0   \n",
      "2 2020-01-01 22:43:12  2.142916e+06  594483.930769   939.544285   14.0   \n",
      "3 2020-01-01 22:45:50  2.143009e+06  595432.437744  1078.554285   47.0   \n",
      "4 2020-01-01 22:45:51  2.143006e+06  595424.912236  1081.164285   17.0   \n",
      "\n",
      "                         full_name               Alarma   latitude   longitude  \n",
      "0  Leonardo Guadalupe Lecona Pérez  Exceso de Velocidad  19.379396 -104.090268  \n",
      "1  Leonardo Guadalupe Lecona Pérez  Exceso de Velocidad  19.379394 -104.090195  \n",
      "2        Emmanuel Lizardi Sandoval        Rt R Susp Cyl  19.378149 -104.100267  \n",
      "3  Leonardo Guadalupe Lecona Pérez  Exceso de Velocidad  19.378948 -104.091230  \n",
      "4  Leonardo Guadalupe Lecona Pérez  Exceso de Velocidad  19.378920 -104.091302  \n",
      "Registros después de eliminar nulos y filtrar velocidad: 881 filas\n",
      "Fecha mínima en los datos: 2020-01-01 20:47:38\n",
      "Fecha máxima en los datos: 2020-01-20 23:46:35\n",
      "Empleados disponibles: ['Leonardo Guadalupe Lecona Pérez' 'Emmanuel Lizardi Sandoval'\n",
      " 'Carlos Omar Evangelista Torres' 'Miguel Angel Ojeda Cervantes '\n",
      " 'Sergio De La Cruz Ramos' 'Abraham Ceja Jiménez'\n",
      " 'Juan José Michel Campos' 'J Jesús Cruz Aviña'\n",
      " 'Francisco Javier Serratos Jiménez' 'Hugo Roberto Ramírez Michel'\n",
      " 'Abel Eduardo Villalvazo Romero' 'José Gamaliel Silva Meza'\n",
      " 'Jorge Alberto Lizárraga Méndez' 'Walter Yair De la Cruz Alonzo'\n",
      " 'Rafael De La Cruz Ramos' 'Juan Carlos Mata Gutiérrez'\n",
      " 'Carlos Humberto Ortíz Campos' 'Rigoberto Gutiérrez Curiel'\n",
      " 'Samuel Camacho Torres' 'Armando Javier Zuñiga Baltazar'\n",
      " 'Rubén Lara Virgen' 'Manuel Nuñez Quiñonez' 'Juan Carlos Ochoa Romero '\n",
      " 'Joaquín Montecillo Mejía' 'Víctor Palavicini Silva Moreno'\n",
      " 'Edgar Giovanni López Magaña' 'Víctor Manuel Arreola Martínez'\n",
      " 'Omar Israel Lázaro Manríquez' 'César Alejandro  Martínez Chávez'\n",
      " 'Candido Ramos Padul' 'Mario Alberto Espíritu Magaña'\n",
      " 'Jaime Rodríguez Jiménez' 'Crhistian Ricardo Cruz Baltazar'\n",
      " 'Ramón Donato Figueroa Martínez' 'Abel Campos Martínez'\n",
      " 'José Luis Pulgarín De los Santos' 'José Ceja Cuellar'\n",
      " 'Manuel Michel Cobián' 'Israel Ramírez Ramírez' 'Lázaro Quiñonez Vázquez'\n",
      " 'José Uziel Martínez Gutiérrez' 'Filiberto Michel Nuñez'\n",
      " 'Víctor Hugo Licea Cuellar' 'Nicolás Roblada Martínez'\n",
      " 'Justino Alonzo Martínez' 'Jesús Manuel Arias Campos'\n",
      " 'Francisco Javier Michel Díaz' 'Jorge Enrique Cortés Arias'\n",
      " 'Adrián Arias López' 'Juan Carlos Martínez Chávez'\n",
      " 'Carlos Noé Munguía Romero' 'Eleazar Silva Meza' 'Leonides Molina Cesar'\n",
      " 'Amador Camacho Valdéz' 'Carlos Ortíz Gutiérrez'\n",
      " 'Eder Balleny Campos Mendoza' 'Rubén Munguía Monroy'\n",
      " 'Vicente Heredia Gudiño' 'Aristeo Martínez Martínez'\n",
      " 'Francisco Silva Perez' 'Anselmo Montes De Oca Munguía'\n",
      " 'Edgar Dioney Torres Quiñonez']\n",
      "Datos filtrados:\n",
      "                                time             j              i  \\\n",
      "count                            833  8.330000e+02     833.000000   \n",
      "mean   2020-01-06 16:07:49.997598720  2.143180e+06  594877.300156   \n",
      "min              2020-01-01 20:47:38  2.140574e+06  591028.242635   \n",
      "25%              2020-01-02 22:28:08  2.142959e+06  594639.202748   \n",
      "50%              2020-01-05 21:56:38  2.143430e+06  594850.942320   \n",
      "75%              2020-01-07 23:58:18  2.143543e+06  595224.145719   \n",
      "max              2020-01-14 23:57:48  2.148849e+06  614200.706955   \n",
      "std                              NaN  5.940643e+02    1003.417216   \n",
      "\n",
      "          Elevation       Speed    latitude   longitude  \n",
      "count    833.000000  833.000000  833.000000  833.000000  \n",
      "mean    1079.160540   17.303721   19.380522 -104.096508  \n",
      "min       41.234285    0.000000   19.357144 -104.133283  \n",
      "25%     1050.724285    8.000000   19.378508 -104.098763  \n",
      "50%     1100.754285   17.000000   19.382761 -104.096758  \n",
      "75%     1131.854285   26.000000   19.383796 -104.093197  \n",
      "max    11803.694285   50.000000   19.430732 -103.912178  \n",
      "std      500.740266   12.421976    0.005335    0.009576  \n",
      "                 time             j              i    Elevation  Speed  \\\n",
      "1 2020-01-01 22:27:10  2.143059e+06  595540.878338  1113.924285   22.0   \n",
      "2 2020-01-01 22:43:12  2.142916e+06  594483.930769   939.544285   14.0   \n",
      "3 2020-01-01 22:45:50  2.143009e+06  595432.437744  1078.554285   47.0   \n",
      "4 2020-01-01 22:45:51  2.143006e+06  595424.912236  1081.164285   17.0   \n",
      "5 2020-01-01 22:46:38  2.142615e+06  594810.744282   997.284285   15.0   \n",
      "\n",
      "                         full_name               Alarma   latitude   longitude  \n",
      "1  Leonardo Guadalupe Lecona Pérez  Exceso de Velocidad  19.379394 -104.090195  \n",
      "2        Emmanuel Lizardi Sandoval        Rt R Susp Cyl  19.378149 -104.100267  \n",
      "3  Leonardo Guadalupe Lecona Pérez  Exceso de Velocidad  19.378948 -104.091230  \n",
      "4  Leonardo Guadalupe Lecona Pérez  Exceso de Velocidad  19.378920 -104.091302  \n",
      "5        Emmanuel Lizardi Sandoval        Rt R Susp Cyl  19.375416 -104.097170  \n",
      "GeoTIFF cargado con dimensiones: (15162, 13418)\n",
      "Límites del GeoTIFF: BoundingBox(left=592029.883, bottom=2140689.959, right=596055.4330000001, top=2145238.559)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:41:49.420 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\mswde\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap, Fullscreen, FloatImage\n",
    "from sqlalchemy import create_engine\n",
    "import utm\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from streamlit_folium import folium_static\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Detalles de la conexión\n",
    "server = '192.168.200.31'\n",
    "database = 'jmineops'\n",
    "username = 'tinformacion'\n",
    "password = 'Timeinlondon$'\n",
    "conn_str = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# Consulta SQL para seleccionar los primeros 100000 registros de la tabla\n",
    "query = \"\"\"\n",
    "SELECT TOP 1000 [time]\n",
    "      ,[Northing] AS j\n",
    "      ,[Easting] AS i\n",
    "      ,[Elevation]\n",
    "      ,[speed] AS Speed\n",
    "      ,[full_name]\n",
    "      ,[Alarma]\n",
    "  FROM [jmineops].[dbo].[T_sensors_speed_coord]\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar la consulta y cargar los datos en un DataFrame\n",
    "data = pd.read_sql(query, engine)\n",
    "\n",
    "# Verificar cuántos registros se cargaron\n",
    "print(f\"Registros cargados: {data.shape[0]} filas y {data.shape[1]} columnas\")\n",
    "\n",
    "# Convertir las coordenadas UTM a latitud y longitud\n",
    "def utm_to_latlon(row):\n",
    "    lat, lon = utm.to_latlon(row['i'], row['j'], 13, 'N')  # Ajustar la zona y el hemisferio según sea necesario\n",
    "    return pd.Series([lat, lon])\n",
    "\n",
    "data[['latitude', 'longitude']] = data.apply(utm_to_latlon, axis=1)\n",
    "\n",
    "# Mostrar las primeras filas después de la conversión de coordenadas\n",
    "print(\"Después de convertir UTM a lat/lon:\")\n",
    "print(data.head())\n",
    "\n",
    "# Filtrar datos para eliminar coordenadas inválidas\n",
    "valid_lat_range = (18, 22)\n",
    "valid_lon_range = (-107, -100)\n",
    "data = data[(data['latitude'].between(*valid_lat_range)) & (data['longitude'].between(*valid_lon_range))]\n",
    "\n",
    "# Convertir la columna 'time' a datetime\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Eliminar filas con valores faltantes y velocidades mayores a 50 km/h\n",
    "data = data.dropna(subset=['latitude', 'longitude', 'Speed', 'Alarma', 'Elevation'])\n",
    "data = data[data['Speed'] <= 50]\n",
    "\n",
    "# Verificar la cantidad de registros después de filtrar nulos y velocidad\n",
    "print(f\"Registros después de eliminar nulos y filtrar velocidad: {data.shape[0]} filas\")\n",
    "\n",
    "# Imprimir rango de fechas y lista de empleados para verificar\n",
    "print(\"Fecha mínima en los datos:\", data['time'].min())\n",
    "print(\"Fecha máxima en los datos:\", data['time'].max())\n",
    "print(\"Empleados disponibles:\", data['full_name'].unique())\n",
    "\n",
    "# Ajustar los filtros de fecha y empleado\n",
    "start_date = pd.to_datetime('2020-01-01')  # Dentro del rango de datos\n",
    "end_date = pd.to_datetime('2020-01-20')    # Dentro del rango de datos\n",
    "employee = 'Todos'  # Cambiar a un nombre específico si es necesario\n",
    "\n",
    "# Filtrar datos según los filtros seleccionados\n",
    "filtered_data = data[\n",
    "    (data['time'] >= start_date) &\n",
    "    (data['time'] <= end_date)\n",
    "]\n",
    "\n",
    "if employee != 'Todos':\n",
    "    filtered_data = filtered_data[filtered_data['full_name'] == employee]\n",
    "\n",
    "# Verificar si el DataFrame filtrado está vacío\n",
    "if filtered_data.empty:\n",
    "    print(\"El DataFrame filtrado está vacío. Verifica los filtros de fecha y empleado.\")\n",
    "else:\n",
    "    # Imprimir estadísticas básicas del DataFrame filtrado\n",
    "    print(\"Datos filtrados:\")\n",
    "    print(filtered_data.describe())\n",
    "    print(filtered_data.head())\n",
    "\n",
    "    # Crear una imagen de la barra de colores\n",
    "    def create_colorbar():\n",
    "        fig, ax = plt.subplots(figsize=(1, 8))\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "        norm = plt.Normalize(vmin=0, vmax=50)\n",
    "        fig.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), cax=ax, orientation='vertical', label='Velocidad (km/h)')\n",
    "        plt.savefig('colorbar.png', bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.close()\n",
    "\n",
    "    create_colorbar()\n",
    "\n",
    "    # Función para reducir el tamaño del GeoTIFF usando rasterio\n",
    "    def reduce_geotiff_with_rasterio(input_path, output_path, scale_factor=0.5):\n",
    "        \"\"\"Reduce el tamaño del GeoTIFF usando rasterio.\"\"\"\n",
    "        with rasterio.open(input_path) as src:\n",
    "            # Calcular nuevas dimensiones\n",
    "            new_width = int(src.width * scale_factor)\n",
    "            new_height = int(src.height * scale_factor)\n",
    "\n",
    "            # Redimensionar y guardar el nuevo archivo\n",
    "            data = src.read(\n",
    "                out_shape=(\n",
    "                    src.count,\n",
    "                    new_height,\n",
    "                    new_width\n",
    "                ),\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "\n",
    "            transform = src.transform * src.transform.scale(\n",
    "                (src.width / data.shape[-1]),\n",
    "                (src.height / data.shape[-2])\n",
    "            )\n",
    "\n",
    "            # Guardar el archivo reducido\n",
    "            with rasterio.open(\n",
    "                output_path,\n",
    "                'w',\n",
    "                driver='GTiff',\n",
    "                height=new_height,\n",
    "                width=new_width,\n",
    "                count=src.count,\n",
    "                dtype=data.dtype,\n",
    "                crs=src.crs,\n",
    "                transform=transform,\n",
    "            ) as dst:\n",
    "                dst.write(data)\n",
    "\n",
    "    # Rutas de los archivos GeoTIFF\n",
    "    input_geotiff_path = 'Pea-Colorada-PeCo_Orto_Feb2024-57-dsm.tif'\n",
    "    reduced_geotiff_path = 'reduced_Pea-Colorada-PeCo_Orto_Feb2024-57-dsm.tif'\n",
    "\n",
    "    # Reducir el tamaño del archivo GeoTIFF a un 50% de su tamaño original\n",
    "    reduce_geotiff_with_rasterio(input_geotiff_path, reduced_geotiff_path, scale_factor=0.5)\n",
    "\n",
    "    # Cargar el archivo GeoTIFF reducido\n",
    "    with rasterio.open(reduced_geotiff_path) as src:\n",
    "        bounds = src.bounds\n",
    "        img = src.read(1)\n",
    "\n",
    "    # Verificar las dimensiones y los límites del archivo GeoTIFF\n",
    "    print(f\"GeoTIFF cargado con dimensiones: {img.shape}\")\n",
    "    print(f\"Límites del GeoTIFF: {bounds}\")\n",
    "\n",
    "    # Calcular el centro del mapa\n",
    "    latitude_mean = filtered_data['latitude'].mean()\n",
    "    longitude_mean = filtered_data['longitude'].mean()\n",
    "\n",
    "    if pd.isna(latitude_mean) or pd.isna(longitude_mean):\n",
    "        print(\"No se pueden calcular las medias de latitud o longitud. Verifica los datos.\")\n",
    "    else:\n",
    "        # Mapa de velocidad\n",
    "        speed_map_center = [latitude_mean, longitude_mean]\n",
    "        speed_map = folium.Map(location=speed_map_center, zoom_start=13)\n",
    "\n",
    "        # Añadir el GeoTIFF al mapa usando ImageOverlay\n",
    "        folium.raster_layers.ImageOverlay(\n",
    "            image=img,\n",
    "            bounds=[[bounds.bottom, bounds.left], [bounds.top, bounds.right]],\n",
    "            opacity=0.6,\n",
    "            interactive=True,\n",
    "            cross_origin=False,\n",
    "            zindex=1\n",
    "        ).add_to(speed_map)\n",
    "\n",
    "        folium.TileLayer(\n",
    "            tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "            attr='Esri',\n",
    "            name='Esri Satellite',\n",
    "            overlay=False,\n",
    "            control=True\n",
    "        ).add_to(speed_map)\n",
    "\n",
    "        Fullscreen(position='topright', title='Pantalla completa', title_cancel='Salir de pantalla completa').add_to(speed_map)\n",
    "\n",
    "        heatmap_data = filtered_data[['latitude', 'longitude', 'Speed']].dropna().values.tolist()\n",
    "        HeatMap(\n",
    "            heatmap_data,\n",
    "            min_opacity=0.2,  # Reducir la opacidad mínima para hacer los puntos menos prominentes\n",
    "            radius=8,  # Reducir el radio de los puntos\n",
    "            blur=6,  # Reducir el desenfoque de los puntos\n",
    "            max_zoom=1,\n",
    "            gradient={0.0: 'blue', 0.5: 'lime', 1.0: 'red'}\n",
    "        ).add_to(speed_map)\n",
    "\n",
    "        FloatImage('colorbar.png', bottom=5, left=5).add_to(speed_map)\n",
    "\n",
    "        # Mostrar el mapa\n",
    "        folium_static(speed_map)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
